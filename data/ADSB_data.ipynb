{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import connectorx as cx\n",
    "from atfm.preprocess import preprocess\n",
    "from atfm.utils import map_RWY, map_corridors\n",
    "from atfm.utils import check_eligible\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def calculate_unit_vectors(flt_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the unit vectors of the trajectory DataFrame.\n",
    "    Input:\n",
    "        flt_df: A DataFrame containing the trajectory data of a single flight.\n",
    "    Output:\n",
    "        unit_df: A DataFrame containing the unit vectors of the trajectory.\n",
    "    \"\"\"\n",
    "    diff_df = flt_df.diff().dropna() # Create a new DataFrame for the differences\n",
    "    norms = np.sqrt((diff_df**2).sum(axis=1)) # Calculate the norm of each difference vector\n",
    "    unit_df = diff_df.div(norms, axis=0) # Divide each difference vector by its norm to get the unit vectors\n",
    "    unit_df.columns = ['u_x', 'u_y', 'u_z'] # The unit vectors are now stored in unit_df as 'x', 'y', and 'z'\n",
    "\n",
    "    return unit_df\n",
    "\n",
    "def is_smooth(df, threshold):\n",
    "    # Convert the unit vector columns to a numpy array\n",
    "    unit_vectors = df[['u_x', 'u_y', 'u_z']].values\n",
    "\n",
    "    # Calculate the dot product between consecutive unit vectors\n",
    "    dot_products = np.einsum('ij, ij->i', unit_vectors[:-1], unit_vectors[1:])\n",
    "\n",
    "    # Calculate the change in direction angles\n",
    "    direction_changes = np.arccos(np.clip(dot_products, -1.0, 1.0)) * 180 / np.pi\n",
    "\n",
    "    # Apply modulo operation to keep angles within 360 degrees\n",
    "    direction_changes = direction_changes % 360\n",
    "\n",
    "    # Check if any direction change exceeds the threshold\n",
    "    if np.max(direction_changes) <= threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m too_short \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m500\u001B[39m\n\u001B[0;32m      6\u001B[0m too_long \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2000\u001B[39m\n\u001B[1;32m----> 8\u001B[0m ids_arr \u001B[38;5;241m=\u001B[39m \u001B[43mcx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdb_url\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSELECT DISTINCT id FROM \u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[38;5;124;43m WHERE ori_length>=\u001B[39;49m\u001B[38;5;132;43;01m%d\u001B[39;49;00m\u001B[38;5;124;43m AND ori_length<=\u001B[39;49m\u001B[38;5;132;43;01m%d\u001B[39;49;00m\u001B[38;5;124;43m AND arrival=1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mid_tab\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoo_short\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoo_long\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43marrow\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m ids_arr \u001B[38;5;241m=\u001B[39m ids_arr\u001B[38;5;241m.\u001B[39mto_pandas(split_blocks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, date_as_object\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\u001B[38;5;241m.\u001B[39mdropna()\u001B[38;5;241m.\u001B[39msample(frac\u001B[38;5;241m=\u001B[39msample_frac)\n\u001B[0;32m     10\u001B[0m ADSB_arr \u001B[38;5;241m=\u001B[39m cx\u001B[38;5;241m.\u001B[39mread_sql(db_url, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSELECT * FROM %s WHERE flight_id IN (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28mstr\u001B[39m,\u001B[38;5;250m \u001B[39mids_arr\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mT\u001B[38;5;241m.\u001B[39mtolist()[\u001B[38;5;241m0\u001B[39m]))\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m);\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (ADSB_tab), return_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marrow\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ATFM\\lib\\site-packages\\connectorx\\__init__.py:264\u001B[0m, in \u001B[0;36mread_sql\u001B[1;34m(conn, query, return_type, protocol, partition_on, partition_range, partition_num, index_col)\u001B[0m\n\u001B[0;32m    255\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou need to install pyarrow first\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    257\u001B[0m result \u001B[38;5;241m=\u001B[39m _read_sql(\n\u001B[0;32m    258\u001B[0m     conn,\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marrow\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m return_type \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marrow\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpolars\u001B[39m\u001B[38;5;124m\"\u001B[39m} \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marrow2\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    262\u001B[0m     partition_query\u001B[38;5;241m=\u001B[39mpartition_query,\n\u001B[0;32m    263\u001B[0m )\n\u001B[1;32m--> 264\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mreconstruct_arrow\u001B[49m(result)\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_type \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpolars\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpolars2\u001B[39m\u001B[38;5;124m\"\u001B[39m}:\n\u001B[0;32m    266\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "db_url = 'mysql://lics:aelics070@143.248.69.46:13306/atfm_new'\n",
    "id_tab = 'flight'\n",
    "ADSB_tab = 'trajectory'\n",
    "sample_frac = 0.02\n",
    "too_short = 500\n",
    "too_long = 2000\n",
    "\n",
    "ids_arr = cx.read_sql(db_url, \"SELECT DISTINCT id FROM %s WHERE ori_length>=%d AND ori_length<=%d AND arrival=1\" % (id_tab, too_short, too_long), return_type=\"arrow\")\n",
    "ids_arr = ids_arr.to_pandas(split_blocks=False, date_as_object=False).dropna().sample(frac=sample_frac)\n",
    "ADSB_arr = cx.read_sql(db_url, f\"SELECT * FROM %s WHERE flight_id IN ({', '.join(map(str, ids_arr.values.T.tolist()[0]))});\" % (ADSB_tab), return_type=\"arrow\")\n",
    "ADSB_arr = ADSB_arr.to_pandas(split_blocks=False, date_as_object=False).dropna()\n",
    "ADSB_arr['time'] = pd.to_datetime(ADSB_arr['time'], unit='s')\n",
    "\n",
    "\n",
    "ids_dep = cx.read_sql(db_url, \"SELECT DISTINCT id FROM %s WHERE ori_length>=%d AND ori_length<=%d AND arrival=0\" % (id_tab, too_short, too_long), return_type=\"arrow\")\n",
    "ids_dep = ids_dep.to_pandas(split_blocks=False, date_as_object=False).dropna().sample(frac=sample_frac)\n",
    "ADSB_dep = cx.read_sql(db_url, f\"SELECT * FROM %s WHERE flight_id IN ({', '.join(map(str, ids_dep.values.T.tolist()[0]))});\" % (ADSB_tab), return_type=\"arrow\")\n",
    "ADSB_dep = ADSB_dep.to_pandas(split_blocks=False, date_as_object=False).dropna()\n",
    "ADSB_dep['time'] = pd.to_datetime(ADSB_dep['time'], unit='s')\n",
    "\n",
    "ids_arr.shape[0], ids_dep.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "icn_lat, icn_lon, icn_alt = 37.49491667, 126.43033333, 8.0\n",
    "min_alt_change = 2000\n",
    "min_FAF_baro = 1600\n",
    "app_sector_rad = 25\n",
    "target_length = too_long + 1\n",
    "\n",
    "arr_dep = []\n",
    "for ADSB in [ADSB_arr, ADSB_dep]:\n",
    "    print('Processing %s' % ('arrival' if ADSB is ADSB_arr else 'departure'))\n",
    "    num_reject = 0\n",
    "    df_ls = []\n",
    "    for id in tqdm(set(ADSB['flight_id'].values.tolist())):\n",
    "\n",
    "        flt_df = ADSB.loc[ADSB['flight_id'] == id]\n",
    "        flt_df = flt_df.set_index('time')\n",
    "\n",
    "        if not check_eligible(flt_df, min_alt_change, min_FAF_baro, icn_lat, icn_lon, app_sector_rad):\n",
    "            num_reject += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            flt_df = preprocess(flt_df, ref_lat=icn_lat, ref_lon=icn_lon, ref_alt=icn_alt, periods=target_length, max_range_x=150, max_range_y=150, alt_column='baroaltitude')\n",
    "            flt_df = flt_df.dropna()\n",
    "        except Exception:\n",
    "            num_reject += 1\n",
    "            continue\n",
    "\n",
    "        unit_df = calculate_unit_vectors(flt_df)\n",
    "        if not is_smooth(unit_df, 90):\n",
    "            num_reject += 1\n",
    "            continue\n",
    "\n",
    "        joined_df = pd.concat([flt_df, unit_df], axis=1)\n",
    "        joined_df[unit_df.columns] = joined_df[unit_df.columns].shift(-1)\n",
    "        df_ls.append(joined_df)\n",
    "\n",
    "    print('Rejected %d flights' % num_reject)\n",
    "    arr_dep.append(df_ls)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_size = 2000\n",
    "\n",
    "for df_ls in arr_dep:\n",
    "    random.seed(42)  # Set a common seed value for consistent sampling\n",
    "\n",
    "    flt_traj_and_path_ls = [df.dropna().T.to_numpy() for df in df_ls if df.iloc[:, -3:].dropna(how='all').T.shape == (3, target_length-1)]\n",
    "    sampled_data = random.sample(flt_traj_and_path_ls, data_size)\n",
    "\n",
    "    flt_traj_ls = [data[:3, :] for data in sampled_data]\n",
    "    flt_traj_array = np.stack(flt_traj_ls, axis=0)\n",
    "\n",
    "    flt_path_ls = [data[-3:, :] for data in sampled_data]\n",
    "    flt_path_array = np.stack(flt_path_ls, axis=0)\n",
    "\n",
    "    n_train = int(len(flt_path_array) * 0.8)\n",
    "    train_data = flt_path_array[:n_train]\n",
    "    test_data = flt_path_array[n_train:]\n",
    "    train_traj = flt_traj_array[:n_train]\n",
    "    test_traj = flt_traj_array[n_train:]\n",
    "\n",
    "    print(\"Data for Arrival\" if df_ls is arr_dep[0] else \"Data for Departure\")\n",
    "    print(\"Flight Path Dataset Shape ====> \\tTrainset: \", train_data.shape, \"\\tTestset: \", test_data.shape)\n",
    "    print(\"Reference Trajectory Shape ====> \\tTrainset: \", train_traj.shape, \"\\tTestset: \", test_traj.shape)\n",
    "\n",
    "    ## Save signals to file\n",
    "    data_dir = './ADSB_data_arr' if df_ls is arr_dep[0] else './ADSB_data_dep'\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.mkdir(data_dir)\n",
    "    with open(data_dir + '/x_train.pkl', 'wb') as f:\n",
    "        pickle.dump(train_data, f)\n",
    "    with open(data_dir + '/x_test.pkl', 'wb') as f:\n",
    "        pickle.dump(test_data, f)\n",
    "    with open(data_dir + '/traj_train.pkl', 'wb') as f:\n",
    "        pickle.dump(train_traj, f)\n",
    "    with open(data_dir + '/traj_test.pkl', 'wb') as f:\n",
    "        pickle.dump(test_traj, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for df_ls in arr_dep:\n",
    "    fig, axs = plt.subplots(6, figsize=(10, 15))\n",
    "    # x plots\n",
    "    for i, df in enumerate(df_ls):\n",
    "        axs[0].plot(range(len(df)), df['x'])\n",
    "        axs[3].plot(range(len(df)), df['u_x'])\n",
    "    axs[0].set_ylabel('X')\n",
    "    axs[3].set_ylabel('U_X')\n",
    "\n",
    "    # y plots\n",
    "    for i, df in enumerate(df_ls):\n",
    "        axs[1].plot(range(len(df)), df['y'])\n",
    "        axs[4].plot(range(len(df)), df['u_y'])\n",
    "    axs[1].set_ylabel('Y')\n",
    "    axs[4].set_ylabel('U_Y')\n",
    "\n",
    "    # z plots\n",
    "    for i, df in enumerate(df_ls):\n",
    "        axs[2].plot(range(len(df)), df['z'])\n",
    "        axs[5].plot(range(len(df)), df['u_z'])\n",
    "    axs[2].set_ylabel('Z')\n",
    "    axs[5].set_ylabel('U_Z')\n",
    "\n",
    "    # Set the x label for all plots\n",
    "    for ax in axs.flat:\n",
    "        ax.set_xlabel('State')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./ADSB_data/ADSB_%s.png' % ('arrival' if df_ls is arr_dep[0] else 'departure'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "for df_ls in arr_dep:\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    for df in df_ls:\n",
    "        ax.plot(df['x'], df['y'], df['z'])\n",
    "\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    plt.savefig('./ADSB_data/ADSB_3D_%s.png' % ('arrival' if df_ls is arr_dep[0] else 'departure'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "atfm",
   "language": "python",
   "display_name": "ATFM"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
